name: Scrape Tweets to Supabase

on:
  schedule:
    - cron: '0 13 * * *'
    - cron: '30 19 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3'

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends \
            build-essential libpq-dev libssl-dev \
            libcurl4-openssl-dev libxml2-dev \
            python3-dev python3-venv libpng-dev zlib1g-dev

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run twitter_ingest.R
        env:
          SUPABASE_HOST:   ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT:   ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DB:     ${{ secrets.SUPABASE_DB }}
          SUPABASE_USER:   ${{ secrets.SUPABASE_USER }}
          SUPABASE_PWD:    ${{ secrets.SUPABASE_PWD }}

          TW_COOKIES_JSON: ${{ secrets.TW_COOKIES_JSON }}
          TW_HANDLES:      ${{ vars.TW_HANDLES }}

          PY_VENV_PATH:    ".venv"
          TW_DEBUG: "0"
        run: |
          Rscript twitter_ingest.R

      - name: Upload debug HTML
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-http
          path: debug_http/
          if-no-files-found: ignore
